{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Image\n",
      "import math\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "import scipy as sp\n",
      "import scipy.cluster\n",
      "import scipy.misc\n",
      "\n",
      "def load_images(img_dir, grayscale=False):\n",
      "    \"\"\"Loads images from within a specified directory.\n",
      "\n",
      "    Args:\n",
      "      img_dir (str): The directory from which to load (.jpg) images.\n",
      "      grayscale (bool): Whether to convert the image into grayscale. Defaults to False.\n",
      "\n",
      "    Returns:\n",
      "      images: An array of image objects loaded from the specified directory\n",
      "\n",
      "    \"\"\"\n",
      "    images = []\n",
      "\n",
      "    for file in os.listdir(img_dir):\n",
      "        if file.endswith(\".jpg\"):\n",
      "            im = Image.open(os.path.join(img_dir, file))\n",
      "\n",
      "            im = im.resize((100, 100))\n",
      "\n",
      "            if grayscale:\n",
      "                im = np.array(im, dtype=np.float64) / 255\n",
      "\n",
      "                # Convert image to grayscale\n",
      "                r, g, b = im[:,:,0], im[:,:,1], im[:,:,2]\n",
      "                gray = 0.2989*r + 0.5870*g + 0.1140*b\n",
      "                im = gray.reshape((1, -1))[0]\n",
      "\n",
      "            images.append(im)\n",
      "\n",
      "    return images\n",
      "\n",
      "def plot_image_space(images, X, title=\"Projection of the Images into 2 Dimensions\"):\n",
      "    \"\"\"Generates and shows a plot of images in a feature space.\n",
      "\n",
      "    A figure with one plot is generated. The plot displays the location of each image in \n",
      "    relation to the image's feature values in the input feature space (X).\n",
      "\n",
      "    Args:\n",
      "      images (Image): An image.\n",
      "      images (SciPy array): An array of SSQs, one computed for each k.\n",
      "\n",
      "    \"\"\"\n",
      "    # min-max normalization    \n",
      "    x_min, x_max = np.min(X, axis=0), np.max(X, axis=0)\n",
      "    X = (X - x_min) / (x_max - x_min)\n",
      "\n",
      "    # Create a figure\n",
      "    pl.figure(figsize=(16, 5))\n",
      "    ax = pl.subplot(111)\n",
      "    #ax.axis('off')\n",
      "\n",
      "    # Generate picture thumbnails in the plot\n",
      "    if hasattr(matplotlib.offsetbox, 'AnnotationBbox'):\n",
      "        # only print thumbnails with matplotlib > 1.0\n",
      "        for i in range(len(images)):\n",
      "            imagebox = matplotlib.offsetbox.OffsetImage(images[i], zoom=.65)\n",
      "            ab = matplotlib.offsetbox.AnnotationBbox(imagebox, X[i][0:2])                                  \n",
      "            ax.add_artist(ab)\n",
      "\n",
      "    # Add figure labels and ticks\n",
      "    pl.title(title, fontsize=16)\n",
      "    pl.xticks([]), pl.yticks([])\n",
      "\n",
      "    # Add figure bounds\n",
      "    pl.ylim((np.min(X, axis=0)[1])-0.25,(np.max(X, axis=0)[1])+0.25)\n",
      "    pl.xlim((np.min(X, axis=0)[0])-0.1,(np.max(X, axis=0)[0])+0.1)\n",
      "    \n",
      "def plot_gallery(title, images, n_col, n_row):\n",
      "    \"\"\"Generates and shows a plot of images as a gallery.\n",
      "\n",
      "    Args:\n",
      "      title (str): The title of the plot.\n",
      "      images(mxn array): m images with each image composed of n pixels.\n",
      "      n_col: The number of columns in the gallery.\n",
      "      n_row: The number of rows in the gallery.\n",
      "\n",
      "    \"\"\"\n",
      "    pl.figure(figsize=(2.*n_col, 2.26*n_row))\n",
      "    pl.suptitle(title, size=16)\n",
      "    for i, comp in enumerate(images):\n",
      "        pl.subplot(n_row, n_col, i+1)\n",
      "        vmax = max(comp.max(), -comp.min())\n",
      "        pl.imshow(comp.reshape(image_shape), cmap=pl.cm.gray, interpolation='nearest', vmin=-vmax, vmax=vmax)\n",
      "        pl.xticks(())\n",
      "        pl.yticks(())\n",
      "    pl.subplots_adjust(left=0.01, bottom=0., right=0.99, top=0.88, wspace=0.04, hspace=0.)\n",
      "\n",
      "def cluster_image_colors(image, num_clusters=5):\n",
      "    \"\"\"Clusters the colors of an image into a set of prototype colors.\n",
      "\n",
      "    Args:\n",
      "      image (Obj): The image on which to perform clustering.\n",
      "      num_clusters (int): The number of color clusters to generate. Defaults to 5.\n",
      "\n",
      "    Returns:\n",
      "      centroids: A kxN array of centroids found at the last iteration of k-means.\n",
      "      labels: An array of codes or indices, each corresponding to a sample point's closest \n",
      "        centroid.\n",
      "\n",
      "    \"\"\"\n",
      "    ar = sp.misc.fromimage(image)\n",
      "    ar = ar.reshape(np.product(ar.shape[:2]), ar.shape[2])\n",
      "\n",
      "    centroids, labels = sp.cluster.vq.kmeans2(ar, num_clusters)\n",
      "\n",
      "    return centroids, labels\n",
      "\n",
      "def plot_color_palette(image, palette, size=0.8):\n",
      "    \"\"\"Plots a palette of prototype colors for an associated image.\n",
      "\n",
      "    Args:\n",
      "      image (Obj): The image for which to plot a palette.\n",
      "      palette (mxn): The array of colors that will constitute the palette.\n",
      "      size (float): The relative size of the palette plot.\n",
      "\n",
      "    \"\"\"\n",
      "    palette = numpy.divide(palette.astype(float), 255)\n",
      "    n = len(palette)\n",
      "    \n",
      "    # Create a figure\n",
      "    pl.figure()\n",
      "    pl.imshow(image);\n",
      "    pl.axis('off')\n",
      "\n",
      "    # Add figure labels and ticks\n",
      "    pl.title(\"Image and Color Palette\", fontsize=16)\n",
      "    pl.xticks(());\n",
      "    pl.yticks(());\n",
      "\n",
      "    # Create a figure\n",
      "    pl.figure(figsize=(n*size, size))\n",
      "    ax = pl.subplot(111)\n",
      "    ax.imshow(np.arange(n).reshape(1, n),\n",
      "              cmap=mpl.colors.ListedColormap(list(palette)),\n",
      "              interpolation=\"nearest\", aspect=\"auto\")\n",
      "\n",
      "    pl.axis('off')\n",
      "\n",
      "    # Add figure ticks and labels\n",
      "    ax.set_xticks(np.arange(n)-.5)\n",
      "    ax.set_yticks([-.5, .5])\n",
      "    ax.set_xticklabels([])\n",
      "    ax.set_yticklabels([])\n",
      "\n",
      "def recreate_image(codebook, labels, w, h):\n",
      "    \"\"\"Recreates the (compressed) image from the code book and labels.\n",
      "\n",
      "    Args:\n",
      "      codebook (kxN array): The i'th row is the centroid of code word i.\n",
      "      labels (Array): The i'th code or index of the centroid to which the i'th observation is \n",
      "        closest.\n",
      "      w (int): The image width.\n",
      "      h (int): The image height.\n",
      "\n",
      "    \"\"\"\n",
      "    d = codebook.shape[1]\n",
      "    image = np.zeros((w, h, d))\n",
      "    label_idx = 0\n",
      "    for i in range(w):\n",
      "        for j in range(h):\n",
      "            image[i][j] = codebook[labels[label_idx]]\n",
      "            label_idx += 1\n",
      "\n",
      "    return image\n",
      "\n",
      "# (c) 2014 Reid Johnson\n",
      "#\n",
      "# Modified from:\n",
      "# (c) 2013 Mikael Vejdemo-Johansson\n",
      "# BSD License\n",
      "#\n",
      "# SciPy function to compute the gap statistic for evaluating k-means clustering.\n",
      "#\n",
      "# The gap statistic is defined by Tibshirani, Walther, Hastie in:\n",
      "#  Estimating the number of clusters in a data set via the gap statistic\n",
      "#  J. R. Statist. Soc. B (2001) 63, Part 2, pp 411-423\n",
      "\n",
      "import scipy as sp\n",
      "import scipy as sp\n",
      "import scipy.cluster.vq\n",
      "import scipy.spatial.distance\n",
      "import scipy.stats\n",
      "import sklearn.cluster\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "dst = sp.spatial.distance.euclidean\n",
      "\n",
      "def gap_statistics(data, refs=None, nrefs=20, ks=range(1,11)):\n",
      "    \"\"\"Computes the gap statistics for an nxm dataset.\n",
      "\n",
      "    The gap statistic measures the difference between within-cluster dispersion on an input\n",
      "    dataset and that expected under an appropriate reference null distribution.\n",
      "\n",
      "    Computation of the gap statistic, then, requires a series of reference (null) distributions.\n",
      "    One may either input a precomputed set of reference distributions (via the parameter refs)\n",
      "    or specify the number of reference distributions (via the parameter nrefs) for automatic \n",
      "    generation of uniform distributions within the bounding box of the dataset (data).\n",
      "\n",
      "    Each computation of the gap statistic requires the clustering of the input dataset and of\n",
      "    several reference distributions. To identify the optimal number of clusters k, the gap \n",
      "    statistic is computed over a range of possible values of k (via the parameter ks).\n",
      "\n",
      "    For each value of k, within-cluster dispersion is calculated for the input dataset and each\n",
      "    reference distribution. The calculation of the within-cluster dispersion for the reference\n",
      "    distributions will have a degree of variation, which we measure by standard deviation or\n",
      "    standard error.\n",
      "\n",
      "    The estimated optimal number of clusters, then, is defined as the smallest value k such that\n",
      "    gap_k is greater than or equal to the sum of gap_k+1 minus the expected error err_k+1.\n",
      "\n",
      "    Args:\n",
      "      data ((n,m) SciPy array): The dataset on which to compute the gap statistics.\n",
      "      refs ((n,m,k) SciPy array, optional): A precomputed set of reference distributions. \n",
      "        Defaults to None.\n",
      "      nrefs (int, optional): The number of reference distributions for automatic generation. \n",
      "        Defaults to 20.\n",
      "      ks (list, optional): The list of values k for which to compute the gap statistics. \n",
      "        Defaults to range(1,11), which creates a list of values from 1 to 10.\n",
      "\n",
      "    Returns:\n",
      "      gaps: an array of gap statistics computed for each k.\n",
      "      errs: an array of standard errors (se), with one corresponding to each gap computation.\n",
      "      difs: an array of differences between each gap_k and the sum of gap_k+1 minus err_k+1.\n",
      "\n",
      "    \"\"\"\n",
      "    shape = data.shape\n",
      "\n",
      "    if refs==None:\n",
      "        tops = data.max(axis=0) # maxima along the first axis (rows)\n",
      "        bots = data.min(axis=0) # minima along the first axis (rows)\n",
      "        dists = sp.matrix(sp.diag(tops-bots)) # the bounding box of the input dataset\n",
      "\n",
      "        # Generate nrefs uniform distributions each in the half-open interval [0.0, 1.0)\n",
      "        rands = sp.random.random_sample(size=(shape[0],shape[1], nrefs))\n",
      "\n",
      "        # Adjust each of the uniform distributions to the bounding box of the input dataset\n",
      "        for i in range(nrefs):\n",
      "            rands[:,:,i] = rands[:,:,i]*dists+bots\n",
      "    else:\n",
      "        rands = refs\n",
      "\n",
      "    gaps = sp.zeros((len(ks),))   # array for gap statistics (lenth ks)\n",
      "    errs = sp.zeros((len(ks),))   # array for model standard errors (length ks)\n",
      "    difs = sp.zeros((len(ks)-1,)) # array for differences between gaps (length ks-1)\n",
      "\n",
      "    for (i,k) in enumerate(ks): # iterate over the range of k values\n",
      "        # Cluster the input dataset via k-means clustering using the current value of k\n",
      "        try:\n",
      "            (kmc,kml) = sp.cluster.vq.kmeans2(data, k)\n",
      "        except LinAlgError:\n",
      "            kmeans = sklearn.cluster.KMeans(n_clusters=k).fit(data)\n",
      "            (kmc, kml) = kmeans.cluster_centers_, kmeans.labels_\n",
      "\n",
      "        # Generate within-dispersion measure for the clustering of the input dataset\n",
      "        disp = sum([dst(data[m,:],kmc[kml[m],:]) for m in range(shape[0])])\n",
      "\n",
      "        # Generate within-dispersion measures for the clusterings of the reference datasets\n",
      "        refdisps = sp.zeros((rands.shape[2],))\n",
      "        for j in range(rands.shape[2]):\n",
      "            # Cluster the reference dataset via k-means clustering using the current value of k\n",
      "            try:\n",
      "                (kmc,kml) = sp.cluster.vq.kmeans2(rands[:,:,j], k)\n",
      "            except LinAlgError:\n",
      "                kmeans = sklearn.cluster.KMeans(n_clusters=k).fit(rands[:,:,j])\n",
      "                (kmc, kml) = kmeans.cluster_centers_, kmeans.labels_\n",
      "\n",
      "            refdisps[j] = sum([dst(rands[m,:,j],kmc[kml[m],:]) for m in range(shape[0])])\n",
      "\n",
      "        # Compute the (estimated) gap statistic for k\n",
      "        gaps[i] = sp.mean(sp.log(refdisps) - sp.log(disp))\n",
      "\n",
      "        # Compute the expected error for k\n",
      "        errs[i] = sp.sqrt(sum(((sp.log(refdisp)-sp.mean(sp.log(refdisps)))**2) \\\n",
      "                              for refdisp in refdisps)/float(nrefs)) * sp.sqrt(1+1/nrefs)\n",
      "\n",
      "    # Compute the difference between gap_k and the sum of gap_k+1 minus err_k+1\n",
      "    difs = sp.array([gaps[k] - (gaps[k+1]-errs[k+1]) for k in range(len(gaps)-1)])\n",
      "\n",
      "    #print \"Gaps: \" + str(gaps)\n",
      "    #print \"Errs: \" + str(errs)\n",
      "    #print \"Difs: \" + str(difs)\n",
      "\n",
      "    return gaps, errs, difs\n",
      "\n",
      "def plot_gap_statistics(gaps, errs, difs):\n",
      "    \"\"\"Generates and shows plots for the gap statistics.\n",
      "\n",
      "    A figure with two subplots is generated. The first subplot is an errorbar plot of the \n",
      "    estimated gap statistics computed for each value of k. The second subplot is a barplot \n",
      "    of the differences in the computed gap statistics.\n",
      "\n",
      "    Args:\n",
      "      gaps (SciPy array): An array of gap statistics, one computed for each k.\n",
      "      errs (SciPy array): An array of standard errors (se), with one corresponding to each gap \n",
      "        computation.\n",
      "      difs (SciPy array): An array of differences between each gap_k and the sum of gap_k+1 \n",
      "        minus err_k+1.\n",
      "\n",
      "    \"\"\"\n",
      "    # Create a figure\n",
      "    fig = pl.figure(figsize=(16, 4))\n",
      "\n",
      "    pl.subplots_adjust(wspace=0.35) # adjust the distance between figures\n",
      "\n",
      "    # Subplot 1\n",
      "    ax = fig.add_subplot(121)\n",
      "    ind = range(1,len(gaps)+1) # the x values for the gaps\n",
      "\n",
      "    # Create an errorbar plot\n",
      "    rects = ax.errorbar(ind, gaps, yerr=errs, xerr=None, linewidth=1.0)\n",
      "\n",
      "    # Add figure labels and ticks\n",
      "    ax.set_title('Clustering Gap Statistics', fontsize=16)\n",
      "    ax.set_xlabel('Number of clusters k', fontsize=14)\n",
      "    ax.set_ylabel('Gap Statistic', fontsize=14)\n",
      "    ax.set_xticks(ind)\n",
      "\n",
      "    # Add figure bounds\n",
      "    ax.set_ylim(0, max(gaps+errs)*1.1)\n",
      "    ax.set_xlim(0, len(gaps)+1.0)\n",
      "\n",
      "    # Subplot 2\n",
      "    ax = fig.add_subplot(122)\n",
      "    ind = range(1,len(difs)+1) # the x values for the difs\n",
      "    \n",
      "    max_gap = None\n",
      "    if len(np.where(difs > 0)[0]) > 0:\n",
      "        max_gap = np.where(difs > 0)[0][0] + 1 # the k with the first positive dif\n",
      "\n",
      "    # Create a bar plot\n",
      "    ax.bar(ind, difs, alpha=0.5, color='g', align='center')\n",
      "\n",
      "    # Add figure labels and ticks\n",
      "    if max_gap:\n",
      "        ax.set_title('Clustering Gap Differences\\n(k=%d Estimated as Optimal)' % (max_gap), \\\n",
      "                     fontsize=16)\n",
      "    else:\n",
      "        ax.set_title('Clustering Gap Differences\\n', fontsize=16)\n",
      "    ax.set_xlabel('Number of clusters k', fontsize=14)\n",
      "    ax.set_ylabel('Gap Difference', fontsize=14)\n",
      "    ax.xaxis.set_ticks(range(1,len(difs)+1))\n",
      "\n",
      "    # Add figure bounds\n",
      "    ax.set_ylim(min(difs)*1.2, max(difs)*1.2)\n",
      "    ax.set_xlim(0, len(difs)+1.0)\n",
      "\n",
      "    # Show the figure\n",
      "    pl.show()\n",
      "\n",
      "# (c) 2014 Reid Johnson\n",
      "# BSD License\n",
      "#\n",
      "# Function to compute the sum of squared distance (SSQ) for evaluating k-means clustering.\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import sklearn.cluster\n",
      "from scipy.spatial.distance import cdist, pdist\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "def ssq_statistics(data, ks=range(1,11), ssq_norm=True):\n",
      "    \"\"\"Computes the sum of squares for an nxm dataset.\n",
      "\n",
      "    The sum of squares (SSQ) is a measure of within-cluster variation that measures the sum of \n",
      "    squared distances from cluster prototypes.\n",
      "\n",
      "    Each computation of the SSQ requires the clustering of the input dataset. To identify the \n",
      "    optimal number of clusters k, the SSQ is computed over a range of possible values of k \n",
      "    (via the parameter ks). For each value of k, within-cluster dispersion is calculated for the \n",
      "    input dataset.\n",
      "\n",
      "    The estimated optimal number of clusters, then, is defined as the value of k prior to an\n",
      "    \"elbow\" point in the plot of SSQ values.\n",
      "\n",
      "    Args:\n",
      "      data ((n,m) SciPy array): The dataset on which to compute the gap statistics.\n",
      "      ks (list, optional): The list of values k for which to compute the gap statistics. \n",
      "        Defaults to range(1,11), which creates a list of values from 1 to 10.\n",
      "\n",
      "    Returns:\n",
      "      ssqs: an array of SSQs, one computed for each k.\n",
      "\n",
      "    \"\"\"\n",
      "    ssqs = sp.zeros((len(ks),)) # array for SSQs (lenth ks)\n",
      "\n",
      "    #n_samples, n_features = data.shape # the number of rows (samples) and columns (features)\n",
      "    #if n_samples >= 2500:\n",
      "    #    # Generate a small sub-sample of the data\n",
      "    #    data_sample = shuffle(data, random_state=0)[:1000]\n",
      "    #else:\n",
      "    #    data_sample = data\n",
      "\n",
      "    for (i,k) in enumerate(ks): # iterate over the range of k values        \n",
      "        # Fit the model on the data\n",
      "        kmeans = sklearn.cluster.KMeans(n_clusters=k, random_state=0).fit(data)\n",
      "\n",
      "        # Predict on the data (k-means) and get labels\n",
      "        #labels = kmeans.predict(data)\n",
      "\n",
      "        if ssq_norm:\n",
      "            dist = np.min(cdist(data, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
      "\n",
      "            tot_withinss = sum(dist**2) # Total within-cluster sum of squares\n",
      "            totss = sum(pdist(data)**2) / data.shape[0] # The total sum of squares\n",
      "            betweenss = totss - tot_withinss # The between-cluster sum of squares\n",
      "            ssqs[i] = betweenss/totss*100\n",
      "        else:\n",
      "            # The sum of squared error (SSQ) for k\n",
      "            ssqs[i] = kmeans.inertia_\n",
      "\n",
      "    return ssqs\n",
      "\n",
      "def plot_ssq_statistics(ssqs):\n",
      "    \"\"\"Generates and shows plots for the sum of squares (SSQ).\n",
      "\n",
      "    A figure with one plot is generated. The plot is a bar plot of the SSQ computed for each \n",
      "    value of k.\n",
      "\n",
      "    Args:\n",
      "      ssqs (SciPy array): An array of SSQs, one computed for each k.\n",
      "\n",
      "    \"\"\"\n",
      "    # Create a figure\n",
      "    fig = pl.figure(figsize=(6.75, 4))\n",
      "\n",
      "    ind = range(1,len(ssqs)+1) # the x values for the ssqs\n",
      "    width = 0.5 # the width of the bars\n",
      "\n",
      "    # Create a bar plot\n",
      "    #rects = pl.bar(ind, ssqs, width)\n",
      "    pl.plot(ind, ssqs)\n",
      "\n",
      "    # Add figure labels and ticks\n",
      "    pl.title('Clustering Sum of Squared Distances', fontsize=16)\n",
      "    pl.xlabel('Number of clusters k', fontsize=14)\n",
      "    pl.ylabel('Sum of Squared Distance (SSQ)', fontsize=14)\n",
      "    pl.xticks(ind)\n",
      "\n",
      "    # Add text labels\n",
      "    #for rect in rects:\n",
      "    #    height = rect.get_height()\n",
      "    #    pl.text(rect.get_x()+rect.get_width()/2., 1.05*height, '%d' % int(height), \\\n",
      "    #            ha='center', va='bottom')\n",
      "\n",
      "    # Add figure bounds\n",
      "    pl.ylim(0, max(ssqs)*1.2)\n",
      "    pl.xlim(0, len(ssqs)+1.0)\n",
      "\n",
      "    pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}
